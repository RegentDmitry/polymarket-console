#!/usr/bin/env python3
"""
–ú–æ–¥—É–ª—å –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö earthquake —Ä—ã–Ω–∫–æ–≤.

–°–∫–∞—á–∏–≤–∞–µ—Ç:
1. –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–æ–±—ã—Ç–∏–π –∏–∑ Gamma API (--metadata)
2. –ò—Å—Ç–æ—Ä–∏—é –∑–µ–º–ª–µ—Ç—Ä—è—Å–µ–Ω–∏–π –∏–∑ USGS (--usgs)
3. –ò—Å—Ç–æ—Ä–∏—é —Å–¥–µ–ª–æ–∫ –∏–∑ –±–ª–æ–∫—á–µ–π–Ω–∞ Polygon (--blockchain)
4. –ò—Å—Ç–æ—Ä–∏—é —Å–¥–µ–ª–æ–∫ –∏–∑ Dune Analytics (--dune --query-id ID)

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python history_downloader.py                    # –°–∫–∞—á–∞—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ + USGS
    python history_downloader.py --metadata         # –¢–æ–ª—å–∫–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    python history_downloader.py --usgs             # –¢–æ–ª—å–∫–æ USGS –¥–∞–Ω–Ω—ã–µ
    python history_downloader.py --blockchain       # –°–¥–µ–ª–∫–∏ –∏–∑ –±–ª–æ–∫—á–µ–π–Ω–∞ (100k –±–ª–æ–∫–æ–≤)
    python history_downloader.py --blockchain --blocks 500000  # –ë–æ–ª—å—à–µ –±–ª–æ–∫–æ–≤
    python history_downloader.py --dune --query-id 123456      # –°–¥–µ–ª–∫–∏ –∏–∑ Dune

–î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ history/:
    - closed/*.json   - –∑–∞–∫—Ä—ã—Ç—ã–µ —Å–æ–±—ã—Ç–∏—è
    - open/*.json     - –æ—Ç–∫—Ä—ã—Ç—ã–µ —Å–æ–±—ã—Ç–∏—è
    - trades/*.json   - –∏—Å—Ç–æ—Ä–∏—è —Å–¥–µ–ª–æ–∫
    - usgs/*.json     - –¥–∞–Ω–Ω—ã–µ –æ –∑–µ–º–ª–µ—Ç—Ä—è—Å–µ–Ω–∏—è—Ö
    - summary.json    - —Å–≤–æ–¥–∫–∞
"""

import argparse
import json
import os
import time
from dataclasses import dataclass, asdict
from datetime import datetime, timezone, timedelta
from pathlib import Path
from typing import Optional

import httpx
from dotenv import load_dotenv

load_dotenv()

# –î–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
BASE_DIR = Path(__file__).parent
HISTORY_DIR = BASE_DIR / "history"
CLOSED_DIR = HISTORY_DIR / "closed"
OPEN_DIR = HISTORY_DIR / "open"
TRADES_DIR = HISTORY_DIR / "trades"
USGS_DIR = HISTORY_DIR / "usgs"

# API URLs
GAMMA_API = "https://gamma-api.polymarket.com"
CLOB_API = os.getenv("CLOB_API_URL", "https://clob.polymarket.com")
USGS_API = "https://earthquake.usgs.gov/fdsnws/event/1"

# Polygon RPC (QuikNode –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç 2000 –±–ª–æ–∫–æ–≤ –∑–∞ –∑–∞–ø—Ä–æ—Å)
POLYGON_RPC = os.getenv("POLYGON_RPC", "https://polygon-mainnet.g.alchemy.com/v2/demo")

# CTFExchange –∫–æ–Ω—Ç—Ä–∞–∫—Ç (Polymarket)
CTF_EXCHANGE = "0x4bFb41d5B3570DeFd03C39a9A4D8dE6Bd8B8982E"

# OrderFilled event signature (–∏–∑ —Ä–µ–∞–ª—å–Ω—ã—Ö –ª–æ–≥–æ–≤ –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞)
ORDER_FILLED_TOPIC = "0xd0a08e8c493f9c94f29311604c9de1b4e8c8d4c06bd0c789af57f2d65bfec0f6"

# CLOB credentials
CLOB_API_KEY = os.getenv("CLOB_API_KEY", "")
CLOB_SECRET = os.getenv("CLOB_SECRET", "")
CLOB_PASS_PHRASE = os.getenv("CLOB_PASS_PHRASE", "")

# Dune Analytics
DUNE_API_KEY = os.getenv("DUNE_API_KEY", "")


# ============================================================================
# DATA CLASSES
# ============================================================================

@dataclass
class Trade:
    """–û–¥–Ω–∞ —Å–¥–µ–ª–∫–∞."""
    timestamp: str
    price: float
    size: float
    side: str  # "BUY" or "SELL"

@dataclass
class PricePoint:
    """–¶–µ–Ω–∞ –Ω–∞ –º–æ–º–µ–Ω—Ç –≤—Ä–µ–º–µ–Ω–∏."""
    timestamp: str
    price: float
    volume_24h: float = 0


# ============================================================================
# GAMMA API - –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–æ–±—ã—Ç–∏–π
# ============================================================================

# –í—Å–µ earthquake —Å–æ–±—ã—Ç–∏—è
EARTHQUAKE_SLUGS = {
    "closed": [
        "megaquake-in-february",
        "6pt0-earthquake-in-mediterranean-by-next-friday",
        "megaquake-in-january",
        "megaquake-in-december",
        "megaquake-in-november",
        "megaquake-in-october",
        "megaquake-in-september",
        "megaquake-in-august",
        "will-an-earthquake-measuring-80-or-above-occur-anywhere-on-earth-before-june-1-2022",
        "will-there-be-an-earthquake-of-magnitude-4pt5-or-higher-in-the-conterminous-us-by-december-31st",
        "will-there-be-an-earthquake-of-magnitude-4pt5-or-higher-in-conterminous-us-by-november-29",
    ],
    "open": [
        "megaquake-by-january-31",
        "megaquake-by-march-31",
        "megaquake-by-june-30",
        "how-many-7pt0-or-above-earthquakes-by-june-30",
        "how-many-7pt0-or-above-earthquakes-in-2026",
        "9pt0-or-above-earthquake-before-2027",
        "10pt0-or-above-earthquake-before-2027",
    ],
}


def download_event_metadata(slug: str, output_dir: Path) -> Optional[dict]:
    """–°–∫–∞—á–∞—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è –∏–∑ Gamma API."""
    try:
        r = httpx.get(f"{GAMMA_API}/events?slug={slug}", timeout=30)
        data = r.json()

        if not data:
            print(f"  ‚ùå {slug}: –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
            return None

        event = data[0]

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º
        filepath = output_dir / f"{slug}.json"
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(event, f, indent=2, ensure_ascii=False)

        title = event.get('title', '')
        volume = event.get('volume', 0)
        print(f"  ‚úÖ {title} (${volume:,.0f})")

        return event

    except Exception as e:
        print(f"  ‚ùå {slug}: {e}")
        return None


def download_all_metadata():
    """–°–∫–∞—á–∞—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤—Å–µ—Ö —Å–æ–±—ã—Ç–∏–π."""
    print("\n" + "=" * 60)
    print("–°–ö–ê–ß–ò–í–ê–ù–ò–ï –ú–ï–¢–ê–î–ê–ù–ù–´–• –°–û–ë–´–¢–ò–ô (Gamma API)")
    print("=" * 60)

    CLOSED_DIR.mkdir(parents=True, exist_ok=True)
    OPEN_DIR.mkdir(parents=True, exist_ok=True)

    all_events = []

    print(f"\nüìÅ –ó–∞–∫—Ä—ã—Ç—ã–µ —Å–æ–±—ã—Ç–∏—è ({len(EARTHQUAKE_SLUGS['closed'])}):\n")
    for slug in EARTHQUAKE_SLUGS['closed']:
        event = download_event_metadata(slug, CLOSED_DIR)
        if event:
            all_events.append(event)
        time.sleep(0.2)  # Rate limiting

    print(f"\nüìÅ –û—Ç–∫—Ä—ã—Ç—ã–µ —Å–æ–±—ã—Ç–∏—è ({len(EARTHQUAKE_SLUGS['open'])}):\n")
    for slug in EARTHQUAKE_SLUGS['open']:
        event = download_event_metadata(slug, OPEN_DIR)
        if event:
            all_events.append(event)
        time.sleep(0.2)

    # –°–≤–æ–¥–∫–∞
    summary = {
        "generated_at": datetime.now(timezone.utc).isoformat(),
        "total_events": len(all_events),
        "total_volume": sum(e.get('volume', 0) for e in all_events),
    }

    with open(HISTORY_DIR / "summary.json", 'w') as f:
        json.dump(summary, f, indent=2)

    print(f"\n‚úÖ –°–∫–∞—á–∞–Ω–æ {len(all_events)} —Å–æ–±—ã—Ç–∏–π")
    return all_events


# ============================================================================
# CLOB API - –ò—Å—Ç–æ—Ä–∏—è —Å–¥–µ–ª–æ–∫
# ============================================================================

def get_clob_headers() -> dict:
    """–ü–æ–ª—É—á–∏—Ç—å –∑–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è CLOB API."""
    if not CLOB_API_KEY:
        return {}
    return {
        "Authorization": f"Bearer {CLOB_API_KEY}",
    }


def download_trades_for_market(condition_id: str, slug: str) -> list[dict]:
    """–°–∫–∞—á–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é —Å–¥–µ–ª–æ–∫ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ä—ã–Ω–∫–∞."""
    trades = []

    try:
        # –ü—Ä–æ–±—É–µ–º –ø—É–±–ª–∏—á–Ω—ã–π endpoint
        r = httpx.get(
            f"{CLOB_API}/trades",
            params={"market": condition_id, "limit": 500},
            headers=get_clob_headers(),
            timeout=30,
        )

        if r.status_code == 200:
            data = r.json()
            if isinstance(data, list):
                trades = data
            elif isinstance(data, dict) and 'trades' in data:
                trades = data['trades']
        elif r.status_code == 401:
            print(f"    ‚ö†Ô∏è  –¢—Ä–µ–±—É–µ—Ç—Å—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è {slug}")
        else:
            print(f"    ‚ö†Ô∏è  HTTP {r.status_code} –¥–ª—è {slug}")

    except Exception as e:
        print(f"    ‚ùå –û—à–∏–±–∫–∞: {e}")

    return trades




# ============================================================================
# USGS API - –ò—Å—Ç–æ—Ä–∏—è –∑–µ–º–ª–µ—Ç—Ä—è—Å–µ–Ω–∏–π
# ============================================================================

def download_usgs_history(
    start_date: datetime,
    end_date: datetime,
    min_magnitude: float = 4.5,
) -> list[dict]:
    """–°–∫–∞—á–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é –∑–µ–º–ª–µ—Ç—Ä—è—Å–µ–Ω–∏–π —Å USGS."""
    earthquakes = []

    try:
        r = httpx.get(
            f"{USGS_API}/query",
            params={
                "format": "geojson",
                "starttime": start_date.strftime("%Y-%m-%d"),
                "endtime": end_date.strftime("%Y-%m-%d"),
                "minmagnitude": min_magnitude,
                "orderby": "time",
            },
            timeout=60,
        )

        if r.status_code == 200:
            data = r.json()
            for feature in data.get('features', []):
                props = feature.get('properties', {})
                earthquakes.append({
                    "id": feature.get('id'),
                    "time": props.get('time'),
                    "magnitude": props.get('mag'),
                    "place": props.get('place'),
                    "url": props.get('url'),
                })
    except Exception as e:
        print(f"  ‚ùå USGS –æ—à–∏–±–∫–∞: {e}")

    return earthquakes


def download_all_usgs():
    """–°–∫–∞—á–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é –∑–µ–º–ª–µ—Ç—Ä—è—Å–µ–Ω–∏–π –¥–ª—è –≤—Å–µ—Ö —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –ø–µ—Ä–∏–æ–¥–æ–≤."""
    print("\n" + "=" * 60)
    print("–°–ö–ê–ß–ò–í–ê–ù–ò–ï –ò–°–¢–û–†–ò–ò –ó–ï–ú–õ–ï–¢–†–Ø–°–ï–ù–ò–ô (USGS)")
    print("=" * 60)

    USGS_DIR.mkdir(parents=True, exist_ok=True)

    # –ü–µ—Ä–∏–æ–¥—ã –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è (–ø–æ –º–∞–≥–Ω–∏—Ç—É–¥–∞–º)
    periods = [
        # M4.5+ –¥–ª—è US —Ä—ã–Ω–∫–æ–≤ 2021
        {
            "name": "m4.5_us_2021",
            "start": datetime(2021, 10, 1),
            "end": datetime(2022, 1, 1),
            "magnitude": 4.5,
        },
        # M6.0+ –¥–ª—è Mediterranean
        {
            "name": "m6.0_2025",
            "start": datetime(2025, 1, 1),
            "end": datetime(2025, 3, 1),
            "magnitude": 6.0,
        },
        # M7.0+ –≥–ª–æ–±–∞–ª—å–Ω–æ (–¥–ª—è —Ç–µ–∫—É—â–∏—Ö —Ä—ã–Ω–∫–æ–≤)
        {
            "name": "m7.0_global_2024_2026",
            "start": datetime(2024, 1, 1),
            "end": datetime(2026, 12, 31),
            "magnitude": 7.0,
        },
        # M8.0+ –≥–ª–æ–±–∞–ª—å–Ω–æ (megaquake)
        {
            "name": "m8.0_global_2020_2026",
            "start": datetime(2020, 1, 1),
            "end": datetime(2026, 12, 31),
            "magnitude": 8.0,
        },
        # M9.0+ –≥–ª–æ–±–∞–ª—å–Ω–æ
        {
            "name": "m9.0_global_2000_2026",
            "start": datetime(2000, 1, 1),
            "end": datetime(2026, 12, 31),
            "magnitude": 9.0,
        },
    ]

    total_quakes = 0

    for period in periods:
        print(f"\nüìä {period['name']} (M{period['magnitude']}+)...")

        quakes = download_usgs_history(
            period['start'],
            period['end'],
            period['magnitude'],
        )

        if quakes:
            filepath = USGS_DIR / f"{period['name']}.json"
            with open(filepath, 'w') as f:
                json.dump({
                    "period": period['name'],
                    "start_date": period['start'].isoformat(),
                    "end_date": period['end'].isoformat(),
                    "min_magnitude": period['magnitude'],
                    "count": len(quakes),
                    "earthquakes": quakes,
                }, f, indent=2)

            print(f"  ‚úÖ {len(quakes)} –∑–µ–º–ª–µ—Ç—Ä—è—Å–µ–Ω–∏–π")
            total_quakes += len(quakes)
        else:
            print(f"  ‚ö†Ô∏è  0 –∑–µ–º–ª–µ—Ç—Ä—è—Å–µ–Ω–∏–π")

        time.sleep(0.5)

    print(f"\n‚úÖ –í—Å–µ–≥–æ —Å–∫–∞—á–∞–Ω–æ {total_quakes} –∑–∞–ø–∏—Å–µ–π –æ –∑–µ–º–ª–µ—Ç—Ä—è—Å–µ–Ω–∏—è—Ö")
    return total_quakes


# ============================================================================
# DUNE ANALYTICS - –ò—Å—Ç–æ—Ä–∏—è —Å–¥–µ–ª–æ–∫
# ============================================================================

DUNE_API = "https://api.dune.com/api/v1"

# –ì–æ—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è earthquake markets
# –°–æ–∑–¥–∞–π —Å–≤–æ–π –∑–∞–ø—Ä–æ—Å –Ω–∞ dune.com –∏ –¥–æ–±–∞–≤—å –µ–≥–æ ID —Å—é–¥–∞
DUNE_QUERIES = {
    # "polymarket_trades": –¢–í–û–ô_QUERY_ID,  # –†–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π –ø–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è
}


def run_dune_query(query_id: int, params: dict = None) -> list[dict]:
    """–í—ã–ø–æ–ª–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å Dune Analytics."""
    if not DUNE_API_KEY:
        print("  ‚ö†Ô∏è  DUNE_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ .env")
        print("  ‚Üí –ü–æ–ª—É—á–∏ –±–µ—Å–ø–ª–∞—Ç–Ω—ã–π –∫–ª—é—á: https://dune.com/settings/api")
        return []

    headers = {"X-Dune-API-Key": DUNE_API_KEY}

    try:
        # –ó–∞–ø—É—Å–∫–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞
        print(f"  –ó–∞–ø—É—Å–∫–∞–µ–º Dune query {query_id}...")
        r = httpx.post(
            f"{DUNE_API}/query/{query_id}/execute",
            headers=headers,
            json={"query_parameters": params or {}},
            timeout=30,
        )

        if r.status_code != 200:
            print(f"  ‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞: {r.status_code} - {r.text[:200]}")
            return []

        execution_id = r.json().get("execution_id")
        if not execution_id:
            print("  ‚ùå –ù–µ—Ç execution_id")
            return []

        # –ñ–¥—ë–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        print(f"  –û–∂–∏–¥–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç (execution_id: {execution_id})...")
        for _ in range(60):  # –ú–∞–∫—Å–∏–º—É–º 5 –º–∏–Ω—É—Ç
            time.sleep(5)

            r = httpx.get(
                f"{DUNE_API}/execution/{execution_id}/status",
                headers=headers,
                timeout=30,
            )
            status = r.json().get("state")
            print(f"    Status: {status}")

            if status == "QUERY_STATE_COMPLETED":
                break
            elif status in ["QUERY_STATE_FAILED", "QUERY_STATE_CANCELLED"]:
                print(f"  ‚ùå Query failed: {status}")
                return []

        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        r = httpx.get(
            f"{DUNE_API}/execution/{execution_id}/results",
            headers=headers,
            timeout=60,
        )

        if r.status_code == 200:
            data = r.json()
            rows = data.get("result", {}).get("rows", [])
            print(f"  ‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {len(rows)} –∑–∞–ø–∏—Å–µ–π")
            return rows
        else:
            print(f"  ‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {r.status_code}")
            return []

    except Exception as e:
        print(f"  ‚ùå Dune error: {e}")
        return []


def create_earthquake_trades_query() -> str:
    """SQL –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–¥–µ–ª–æ–∫ –ø–æ earthquake —Ä—ã–Ω–∫–∞–º."""
    return """
    SELECT
        block_time,
        tx_hash,
        trader,
        side,
        size,
        price,
        outcome,
        market_slug
    FROM polymarket.trades
    WHERE (
        LOWER(market_slug) LIKE '%earthquake%'
        OR LOWER(market_slug) LIKE '%megaquake%'
        OR LOWER(market_slug) LIKE '%9pt0%'
        OR LOWER(market_slug) LIKE '%10pt0%'
        OR LOWER(market_slug) LIKE '%7pt0%'
    )
    ORDER BY block_time DESC
    """


def download_dune_trades(query_id: int = None):
    """–°–∫–∞—á–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é —Å–¥–µ–ª–æ–∫ —á–µ—Ä–µ–∑ Dune Analytics."""
    print("\n" + "=" * 60)
    print("–°–ö–ê–ß–ò–í–ê–ù–ò–ï –ò–°–¢–û–†–ò–ò –°–î–ï–õ–û–ö (Dune Analytics)")
    print("=" * 60)

    if not DUNE_API_KEY:
        print("\n‚ö†Ô∏è  –î–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏ —Å–¥–µ–ª–æ–∫ –Ω—É–∂–µ–Ω Dune API key")
        print("\n–ö–∞–∫ –ø–æ–ª—É—á–∏—Ç—å (–±–µ—Å–ø–ª–∞—Ç–Ω–æ):")
        print("  1. –ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–π—Å—è –Ω–∞ https://dune.com")
        print("  2. –ü–µ—Ä–µ–π–¥–∏ –≤ Settings ‚Üí API")
        print("  3. –°–æ–∑–¥–∞–π API key")
        print("  4. –î–æ–±–∞–≤—å –≤ .env: DUNE_API_KEY=—Ç–≤–æ–π_–∫–ª—é—á")
        return []

    # –ï—Å–ª–∏ query_id –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
    if not query_id:
        query_id = DUNE_QUERIES.get("polymarket_trades")

    if not query_id:
        print("\n‚ö†Ô∏è  –ù—É–∂–µ–Ω query_id –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö")
        print("\n–ö–∞–∫ —Å–æ–∑–¥–∞—Ç—å –∑–∞–ø—Ä–æ—Å –Ω–∞ Dune:")
        print("  1. –ü–µ—Ä–µ–π–¥–∏ –Ω–∞ https://dune.com/queries")
        print("  2. –ù–∞–∂–º–∏ 'New Query'")
        print("  3. –í—Å—Ç–∞–≤—å SQL:")
        print("""
    SELECT
        block_time,
        tx_hash,
        maker as trader,
        taker,
        side,
        size,
        price,
        fee_rate_bps,
        asset_id as token_id
    FROM polymarket_polygon.CTFExchange_evt_OrderFilled
    ORDER BY block_time DESC
    LIMIT 50000
        """)
        print("  4. Run Query ‚Üí Save")
        print("  5. –°–∫–æ–ø–∏—Ä—É–π query_id –∏–∑ URL")
        print("  6. –ó–∞–ø—É—Å—Ç–∏: python history_downloader.py --dune --query-id –¢–í–û–ô_ID")
        return []

    TRADES_DIR.mkdir(parents=True, exist_ok=True)

    print(f"\nüìä –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ (query_id: {query_id})...")

    try:
        headers = {"x-dune-api-key": DUNE_API_KEY}
        r = httpx.get(
            f"{DUNE_API}/query/{query_id}/results",
            headers=headers,
            params={"limit": 50000},
            timeout=120,
        )

        if r.status_code == 200:
            data = r.json()
            rows = data.get("result", {}).get("rows", [])

            print(f"  –ü–æ–ª—É—á–µ–Ω–æ {len(rows)} –∑–∞–ø–∏—Å–µ–π")

            if rows:
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
                filepath = TRADES_DIR / f"dune_trades_{query_id}.json"
                with open(filepath, 'w') as f:
                    json.dump({
                        "source": "dune_analytics",
                        "query_id": query_id,
                        "downloaded_at": datetime.now(timezone.utc).isoformat(),
                        "count": len(rows),
                        "columns": list(rows[0].keys()) if rows else [],
                        "trades": rows,
                    }, f, indent=2)

                print(f"  ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {filepath}")

                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö
                if rows:
                    print(f"\n  –ü—Ä–∏–º–µ—Ä –∑–∞–ø–∏—Å–∏:")
                    for k, v in list(rows[0].items())[:5]:
                        print(f"    {k}: {v}")

                return rows
            else:
                print("  ‚ö†Ô∏è  –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö. –í–æ–∑–º–æ–∂–Ω–æ –∑–∞–ø—Ä–æ—Å –µ—â—ë –Ω–µ –≤—ã–ø–æ–ª–Ω—è–ª—Å—è.")
                print("  ‚Üí –ó–∞–ø—É—Å—Ç–∏ –∑–∞–ø—Ä–æ—Å –Ω–∞ dune.com, –∑–∞—Ç–µ–º –ø–æ–≤—Ç–æ—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ")
        elif r.status_code == 404:
            print(f"  ‚ùå Query {query_id} –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –ø—Ä–∏–≤–∞—Ç–Ω—ã–π")
            print("  ‚Üí –£–±–µ–¥–∏—Å—å —á—Ç–æ query —Å–æ—Ö—Ä–∞–Ω—ë–Ω –∏ –ø—É–±–ª–∏—á–Ω—ã–π")
        else:
            print(f"  ‚ö†Ô∏è  HTTP {r.status_code}: {r.text[:300]}")

    except Exception as e:
        print(f"  ‚ùå –û—à–∏–±–∫–∞: {e}")

    return []


# ============================================================================
# POLYGON RPC - –ò—Å—Ç–æ—Ä–∏—è —Å–¥–µ–ª–æ–∫ –∏–∑ –±–ª–æ–∫—á–µ–π–Ω–∞
# ============================================================================

def load_earthquake_token_ids() -> tuple[set, dict]:
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å –≤—Å–µ token_ids earthquake —Ä—ã–Ω–∫–æ–≤ –∏–∑ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã—Ö –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö.

    Returns:
        tuple: (set of token_ids, dict mapping token_id -> market title)
    """
    token_ids = set()
    token_to_market = {}

    for dir_path in [CLOSED_DIR, OPEN_DIR]:
        if not dir_path.exists():
            continue

        for filepath in dir_path.glob("*.json"):
            try:
                with open(filepath) as f:
                    event = json.load(f)

                title = event.get("title", filepath.stem)

                for market in event.get("markets", []):
                    clob_tokens = market.get("clobTokenIds", "[]")
                    if isinstance(clob_tokens, str):
                        clob_tokens = json.loads(clob_tokens)

                    outcomes = market.get("outcomes", "[]")
                    if isinstance(outcomes, str):
                        outcomes = json.loads(outcomes)

                    for i, token_id in enumerate(clob_tokens):
                        token_ids.add(str(token_id))
                        outcome = outcomes[i] if i < len(outcomes) else "?"
                        token_to_market[str(token_id)] = f"{title} [{outcome}]"

            except Exception as e:
                print(f"  ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {filepath}: {e}")

    return token_ids, token_to_market


def get_current_block() -> int:
    """–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â–∏–π –Ω–æ–º–µ—Ä –±–ª–æ–∫–∞."""
    try:
        r = httpx.post(
            POLYGON_RPC,
            json={"jsonrpc": "2.0", "method": "eth_blockNumber", "params": [], "id": 1},
            timeout=30,
        )
        data = r.json()
        if "error" in data:
            print(f"  ‚ùå RPC error: {data['error']}")
            return 0
        if "result" not in data:
            print(f"  ‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç: {data}")
            return 0
        return int(data["result"], 16)
    except Exception as e:
        print(f"  ‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –±–ª–æ–∫–∞: {e}")
        return 0


def get_block_timestamp(block_number: int) -> int:
    """–ü–æ–ª—É—á–∏—Ç—å timestamp –±–ª–æ–∫–∞."""
    try:
        r = httpx.post(
            POLYGON_RPC,
            json={
                "jsonrpc": "2.0",
                "method": "eth_getBlockByNumber",
                "params": [hex(block_number), False],
                "id": 1,
            },
            timeout=30,
        )
        result = r.json().get("result")
        if result:
            return int(result["timestamp"], 16)
    except:
        pass
    return 0


def fetch_order_filled_logs(from_block: int, to_block: int) -> list:
    """–ü–æ–ª—É—á–∏—Ç—å OrderFilled –ª–æ–≥–∏ –∏–∑ –±–ª–æ–∫—á–µ–π–Ω–∞."""
    try:
        r = httpx.post(
            POLYGON_RPC,
            json={
                "jsonrpc": "2.0",
                "method": "eth_getLogs",
                "params": [{
                    "address": CTF_EXCHANGE,
                    "topics": [ORDER_FILLED_TOPIC],
                    "fromBlock": hex(from_block),
                    "toBlock": hex(to_block),
                }],
                "id": 1,
            },
            timeout=60,
        )

        result = r.json()
        if "error" in result:
            error_msg = result["error"].get("message", "Unknown error")
            if "range" in error_msg.lower():
                return None  # –°–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π –¥–∏–∞–ø–∞–∑–æ–Ω –±–ª–æ–∫–æ–≤
            print(f"  ‚ö†Ô∏è  RPC error: {error_msg}")
            return []

        return result.get("result", [])

    except Exception as e:
        print(f"  ‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –ª–æ–≥–æ–≤: {e}")
        return []


def decode_order_filled(log: dict) -> dict:
    """–î–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å OrderFilled —Å–æ–±—ã—Ç–∏–µ.

    NOTE: –¶–µ–Ω–∞ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è –∫–∞–∫ amount_usd / amount_tokens.
    –ù–∞ Polymarket —Ü–µ–Ω–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å 0-1, –Ω–æ –∏–∑-–∑–∞ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–µ–π –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞
    —Ä–µ–∑—É–ª—å—Ç–∞—Ç –º–æ–∂–µ—Ç –æ—Ç–ª–∏—á–∞—Ç—å—Å—è. –î–ª—è —Ç–æ—á–Ω–æ–≥–æ —Ä–∞—Å—á—ë—Ç–∞ –Ω—É–∂–Ω–æ –∏–∑—É—á–∏—Ç—å
    –ª–æ–≥–∏–∫—É CTFExchange –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞.
    """
    data = log.get("data", "0x")[2:]  # –£–±–∏—Ä–∞–µ–º "0x"

    if len(data) < 320:  # 5 –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø–æ 64 —Å–∏–º–≤–æ–ª–∞
        return None

    try:
        # OrderFilled event data (indexed: orderHash, maker, taker –≤ topics):
        # data[0:64] = side (uint8, 0=BUY, 1=SELL)
        # data[64:128] = assetId (uint256 - token ID)
        # data[128:192] = makerAmountFilled (uint256 - outcome tokens)
        # data[192:256] = takerAmountFilled (uint256 - USDC –≤ raw units)
        # data[256:320] = fee (uint256)

        side = int(data[0:64], 16)  # 0 = BUY, 1 = SELL
        asset_id = str(int(data[64:128], 16))
        maker_amount = int(data[128:192], 16) / 1e6  # Outcome tokens (6 decimals)
        taker_amount = int(data[192:256], 16) / 1e6  # USDC (6 decimals)

        # –¶–µ–Ω–∞ = USDC / outcome tokens
        # TODO: –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å —Ä–∞—Å—á—ë—Ç–∞ –¥–ª—è Polymarket
        if maker_amount > 0:
            price = taker_amount / maker_amount
        else:
            price = 0

        return {
            "block": int(log["blockNumber"], 16),
            "tx_hash": log["transactionHash"],
            "asset_id": asset_id,
            "side": "BUY" if side == 0 else "SELL",
            "amount_usd": taker_amount,  # –°—É–º–º–∞ –≤ USDC
            "amount_tokens": maker_amount,  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤
            "price": round(price, 6),
        }

    except Exception:
        return None


def download_blockchain_trades(
    start_block: int = None,
    blocks_to_scan: int = 100000,
    chunk_size: int = 2000,
):
    """–°–∫–∞—á–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é —Å–¥–µ–ª–æ–∫ –∏–∑ –±–ª–æ–∫—á–µ–π–Ω–∞ Polygon."""
    print("\n" + "=" * 60)
    print("–°–ö–ê–ß–ò–í–ê–ù–ò–ï –ò–°–¢–û–†–ò–ò –°–î–ï–õ–û–ö (Polygon RPC)")
    print("=" * 60)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º earthquake token IDs
    token_ids, token_to_market = load_earthquake_token_ids()
    if not token_ids:
        print("\n‚ö†Ô∏è  –ù–µ –Ω–∞–π–¥–µ–Ω—ã token_ids. –°–Ω–∞—á–∞–ª–∞ —Å–∫–∞—á–∞–π—Ç–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ:")
        print("   python history_downloader.py --metadata")
        return []

    print(f"\nüìä Token IDs –¥–ª—è earthquake —Ä—ã–Ω–∫–æ–≤: {len(token_ids)}")

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω –±–ª–æ–∫–æ–≤
    current_block = get_current_block()
    if not current_block:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â–∏–π –±–ª–æ–∫")
        return []

    if start_block is None:
        start_block = current_block - blocks_to_scan

    print(f"üì¶ –¢–µ–∫—É—â–∏–π –±–ª–æ–∫: {current_block}")
    print(f"üì¶ –°–∫–∞–Ω–∏—Ä—É–µ–º: {start_block} ‚Üí {current_block} ({current_block - start_block} –±–ª–æ–∫–æ–≤)")
    print(f"üì¶ Chunk size: {chunk_size} –±–ª–æ–∫–æ–≤")

    TRADES_DIR.mkdir(parents=True, exist_ok=True)

    all_trades = []
    total_logs = 0
    failed_chunks = 0

    # –°–∫–∞–Ω–∏—Ä—É–µ–º –±–ª–æ–∫–∏ —á–∞–Ω–∫–∞–º–∏
    chunks_total = (current_block - start_block) // chunk_size + 1
    chunk_num = 0

    for from_block in range(start_block, current_block, chunk_size):
        to_block = min(from_block + chunk_size - 1, current_block)
        chunk_num += 1

        # –ü—Ä–æ–≥—Ä–µ—Å—Å
        progress = (chunk_num / chunks_total) * 100
        print(f"\r  [{progress:5.1f}%] –ë–ª–æ–∫–∏ {from_block}-{to_block}...", end="", flush=True)

        logs = fetch_order_filled_logs(from_block, to_block)

        if logs is None:
            # –°–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π –¥–∏–∞–ø–∞–∑–æ–Ω - –ø—Ä–æ–±—É–µ–º –º–µ–Ω—å—à–∏–π chunk
            failed_chunks += 1
            continue

        total_logs += len(logs)

        # –§–∏–ª—å—Ç—Ä—É–µ–º earthquake trades
        for log in logs:
            trade = decode_order_filled(log)
            if trade and trade["asset_id"] in token_ids:
                trade["market"] = token_to_market.get(trade["asset_id"], "Unknown")
                all_trades.append(trade)

        time.sleep(0.1)  # Rate limiting

    print(f"\n\n‚úÖ –ü—Ä–æ—Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–æ {total_logs:,} –ª–æ–≥–æ–≤")
    print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(all_trades)} earthquake trades")

    if failed_chunks > 0:
        print(f"‚ö†Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–æ —á–∞–Ω–∫–æ–≤ (—Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π range): {failed_chunks}")

    if all_trades:
        # –î–æ–±–∞–≤–ª—è–µ–º timestamps –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ –∏ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Ç—Ä–µ–π–¥–∞
        if all_trades:
            first_ts = get_block_timestamp(all_trades[0]["block"])
            last_ts = get_block_timestamp(all_trades[-1]["block"])
        else:
            first_ts = last_ts = 0

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º
        filepath = TRADES_DIR / f"blockchain_trades_{start_block}_{current_block}.json"
        with open(filepath, 'w') as f:
            json.dump({
                "source": "polygon_rpc",
                "downloaded_at": datetime.now(timezone.utc).isoformat(),
                "start_block": start_block,
                "end_block": current_block,
                "total_logs_scanned": total_logs,
                "earthquake_trades_count": len(all_trades),
                "first_trade_timestamp": first_ts,
                "last_trade_timestamp": last_ts,
                "trades": all_trades,
            }, f, indent=2)

        print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {filepath}")

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã
        print(f"\nüìà –ü—Ä–∏–º–µ—Ä—ã —Å–¥–µ–ª–æ–∫:")
        for trade in all_trades[:5]:
            market = trade.get('market', 'Unknown')[:50]
            print(f"  {trade['side']} ${trade['amount_usd']:.2f} - {market}")

    return all_trades


# ============================================================================
# MAIN
# ============================================================================

def main():
    parser = argparse.ArgumentParser(description="–°–∫–∞—á–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ")
    parser.add_argument("--metadata", action="store_true", help="–¢–æ–ª—å–∫–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ")
    parser.add_argument("--trades", action="store_true", help="–¢–æ–ª—å–∫–æ —Å–¥–µ–ª–∫–∏ (Dune)")
    parser.add_argument("--usgs", action="store_true", help="–¢–æ–ª—å–∫–æ USGS")
    parser.add_argument("--dune", action="store_true", help="–¢–æ–ª—å–∫–æ Dune Analytics")
    parser.add_argument("--query-id", type=int, help="Dune query ID –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è")
    parser.add_argument("--blockchain", action="store_true", help="–°–¥–µ–ª–∫–∏ –∏–∑ Polygon –±–ª–æ–∫—á–µ–π–Ω–∞")
    parser.add_argument("--blocks", type=int, default=100000, help="–°–∫–æ–ª—å–∫–æ –±–ª–æ–∫–æ–≤ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞—Ç—å (default: 100000)")
    parser.add_argument("--chunk-size", type=int, default=2000, help="–†–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ –±–ª–æ–∫–æ–≤ (default: 2000)")
    args = parser.parse_args()

    # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ —É–∫–∞–∑–∞–Ω–æ - —Å–∫–∞—á–∏–≤–∞–µ–º –≤—Å—ë (–∫—Ä–æ–º–µ Dune –∏ blockchain)
    download_all = not (args.metadata or args.trades or args.usgs or args.dune or args.blockchain)

    print("=" * 60)
    print("EARTHQUAKE HISTORY DOWNLOADER")
    print("=" * 60)
    print(f"–í—Ä–µ–º—è: {datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M UTC')}")
    print(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {HISTORY_DIR}")

    if download_all or args.metadata:
        download_all_metadata()

    if args.trades or args.dune or args.query_id:
        download_dune_trades(args.query_id)

    if args.blockchain:
        download_blockchain_trades(
            blocks_to_scan=args.blocks,
            chunk_size=args.chunk_size,
        )

    if download_all or args.usgs:
        download_all_usgs()

    print("\n" + "=" * 60)
    print("–ì–û–¢–û–í–û!")
    print("=" * 60)

    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ —Å–∫–∞—á–∞–Ω–æ
    print("\n–°–æ–¥–µ—Ä–∂–∏–º–æ–µ history/:")
    for item in sorted(HISTORY_DIR.rglob("*.json")):
        rel_path = item.relative_to(HISTORY_DIR)
        size = item.stat().st_size / 1024
        print(f"  {rel_path} ({size:.1f} KB)")

    # –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –µ—Å–ª–∏ –Ω–µ—Ç Dune key
    if not DUNE_API_KEY:
        print("\n" + "-" * 60)
        print("üí° –î–ª—è –ø–æ–ª–Ω–æ–π –∏—Å—Ç–æ—Ä–∏–∏ —Å–¥–µ–ª–æ–∫ –¥–æ–±–∞–≤—å –≤ .env:")
        print("   DUNE_API_KEY=—Ç–≤–æ–π_–∫–ª—é—á")
        print("   ‚Üí https://dune.com/settings/api (–±–µ—Å–ø–ª–∞—Ç–Ω–æ)")
        print("-" * 60)


if __name__ == "__main__":
    main()
